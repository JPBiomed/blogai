{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "import fastbook\n",
    "fastbook.setup_book()\n",
    "#hide\n",
    "from fastbook import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apprendre avec Fast AI\n",
    "\n",
    "Cet article fait partie d'une série suivant mon apprentissage du Deep Learning avec fast.ai Suivez le cours vous aussi sur https://www.fast.ai/\n",
    "\n",
    "\n",
    "Dès le deuxième cours, on vise à partager les résultats parce que développer un super algorithme que personne ne peut utiliser parce qu'il est caché sur mon PC, ce n'est pas très intéressant !\n",
    "\n",
    "Alors dans le cours 2, on va :\n",
    "1. Développer un modèle sur base de nos données\n",
    "1. Exporter le modèle\n",
    "1. Rendre ce modèle accessible à tous sur un site web gratuit\n",
    "\n",
    "Allons-y !\n",
    "\n",
    "Et si vous êtes intéressé mais que vous avez encore des questions, écrivez moi, je me ferai un plaisir de répondre à vos questions : jason.pettiaux@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Créer son premier modèle\n",
    "\n",
    "Commençons par choisir un sujet pour mon premier projet.\n",
    "\n",
    "Voilà mes idées:\n",
    "* Classification de pelouse arrosée ou sèche\n",
    "* Créateur de mail pour prendre des nouvelles d'amis\n",
    "* Classification d'images de malaria infectées ou non infectées\n",
    "\n",
    "Avant de lancer mon premier modèle, il faut que j'ai des données.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtenir des données\n",
    "\n",
    "On peut trouver des banques de données en ligne.\n",
    "\n",
    "Voilà les sources de données auxquelles j'ai pensé:\n",
    "* Pelouse : Je vais obtenir les images sur base de l'API de Bing Image (c'est pareil que Google Image)\n",
    "* Mail : Mes derniers messages à des amis et en écrire une dizaine en plus\n",
    "* Malaria : J'ai trouvé des datasets sur Kaggle, une plate-forme de compétition de Data Science, allez voir c'est super intéressant !\n",
    "\n",
    "Pour ce premier projet, je commence par les pelouses !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Je récupère la clé de l'API\n",
    "key = os.environ.get('AZURE_SEARCH_KEY', 'XXX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ErrorResponseException",
     "evalue": "Operation returned an invalid status code 'PermissionDenied'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mErrorResponseException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-cddb73f3292e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearch_images_bing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'grizzly bear'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrgot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'content_url'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.8/site-packages/fastbook/__init__.py\u001b[0m in \u001b[0;36msearch_images_bing\u001b[0;34m(key, term, min_sz)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msearch_images_bing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_sz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://api.cognitive.microsoft.com'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_height\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_sz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_width\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_sz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.8/site-packages/azure/cognitiveservices/search/imagesearch/operations/_images_operations.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, query, accept_language, user_agent, client_id, client_ip, location, aspect, color, country_code, count, freshness, height, id, image_content, image_type, license, market, max_file_size, max_height, max_width, min_file_size, min_height, min_width, offset, safe_search, size, set_lang, width, custom_headers, raw, **operation_config)\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mErrorResponseException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deserialize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0mdeserialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mErrorResponseException\u001b[0m: Operation returned an invalid status code 'PermissionDenied'"
     ]
    }
   ],
   "source": [
    "# Je fais un test\n",
    "results = search_images_bing(key, 'dry lawns')\n",
    "ims = results.attrgot('content_url')\n",
    "len(ims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# J'enregistre l'images pour la visualiser\n",
    "dest = 'images/dry_lawn.jpg'\n",
    "download_url(ims[0], dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Je définis le nom du dossier et les différentes catégories que je vais investiguer\n",
    "bear_types = 'dry',''\n",
    "path = Path('lawns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Je télécharge les images\n",
    "if not path.exists():\n",
    "    path.mkdir()\n",
    "    for o in bear_types:\n",
    "        dest = (path/o)\n",
    "        dest.mkdir(exist_ok=True)\n",
    "        results = search_images_bing(key, f'{o} lawns')\n",
    "        download_images(dest, urls=results.attrgot('content_url'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Je récupère les chemins d'accès\n",
    "fns = get_image_files(path)\n",
    "fns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Je revois les images \n",
    "failed = verify_images(fns)\n",
    "failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Je supprime les mauvaises\n",
    "failed.map(Path.unlink);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Charger les images pour le modèle\n",
    "\n",
    "Un modèle de deep learning a des millions de paramètres comme nous l'avons dit. Donc pour les ajuster tous, cela prend beaucoup de temps. Pour faire cela plus rapidement, on fait l'optimisation en parallèle. Pour ce faire, on utilise un GPU (Graphical Processing Unit) qui est spécialisé dans les calculs en parallèle et on envoie les données par \"batch\" ou par lot en francais.\n",
    "\n",
    "Par défaut, les lots de fast.ai sont de 64 images.\n",
    "\n",
    "Avant d'envoyer ces données, il est nécessaire de les préparer et puis de les rassembler en lot qu'on enverra au GPU. \n",
    "\n",
    "Pour les préparer, fast.ai fournit les `DataBlock` et demandent quelques informations concernant le modèle:\n",
    "\n",
    "* `blocks` : le type de données : dans notre cas, c'est des images d'une part et des catégories d'autre part, (pelouses sèches vs pelouses humides)\n",
    "* `get_items`: le chemin d'accès des images : ici c'est grâce à la fonction `get_image_files`\n",
    "* `splitter` : la division entre ensemble d'entraînement et de validation\n",
    "* `get_y` : la définition des catégories ou de l'ensemble «cible», typiquement appelé y. Ici c'est le type de pelouse. Ici `parent_label` reprendra directement le nom du dossier parent.\n",
    "* `item_tfms` : la méthode de transformation des images : En effet, pour que l'algorithme puisse travailler, il est nécessaire que toutes les images aient la même taille. Classiquement, on choisit de prendre une image carrée. On l'obtenir, on a plusieurs options, qu'on définira avec l'attribut `item_tfms` ici on choisit `Resize` qui va récupérer un carré au centre de l'image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bears = DataBlock(\n",
    "    blocks=(ImageBlock, CategoryBlock), \n",
    "    get_items=get_image_files, \n",
    "    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n",
    "    get_y=parent_label,\n",
    "    item_tfms=Resize(128))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La création d'un `DataBlock` permet de créer des `DataLoaders` quand on fournit le dossier cible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = bears.dataloaders(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant qu'on a chargé les images, il faut encore vérifier qu'elles sont toujours pertinentes et qu'elles n'ont pas été rogné trop fort.\n",
    "\n",
    "On peut faire cela avec la méthode `valid.show_batch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.valid.show_batch(max_n=4, nrows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporter son premier modèle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.42.3 (20191010.1750)\n",
       " -->\n",
       "<!-- Title: G Pages: 1 -->\n",
       "<svg width=\"600pt\" height=\"58pt\"\n",
       " viewBox=\"0.00 0.00 600.38 58.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 54)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-54 596.38,-54 596.38,4 -4,4\"/>\n",
       "<!-- Architecture et Methode d&#39;Apprentissage -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>Architecture et Methode d&#39;Apprentissage</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"452.39,-50 141.39,-50 137.39,-46 137.39,0 448.39,0 452.39,-4 452.39,-50\"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"448.39,-46 137.39,-46 \"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"448.39,-46 448.39,0 \"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"448.39,-46 452.39,-50 \"/>\n",
       "<text text-anchor=\"middle\" x=\"294.89\" y=\"-21.3\" font-family=\"Times,serif\" font-size=\"14.00\">Architecture et Methode d&#39;Apprentissage</text>\n",
       "</g>\n",
       "<!-- Capacité -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>Capacité</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"540.39\" cy=\"-25\" rx=\"51.99\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"540.39\" y=\"-21.3\" font-family=\"Times,serif\" font-size=\"14.00\">Capacité</text>\n",
       "</g>\n",
       "<!-- Architecture et Methode d&#39;Apprentissage&#45;&gt;Capacité -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>Architecture et Methode d&#39;Apprentissage&#45;&gt;Capacité</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M452.51,-25C461.24,-25 469.71,-25 477.71,-25\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"477.96,-28.5 487.96,-25 477.96,-21.5 477.96,-28.5\"/>\n",
       "</g>\n",
       "<!-- Données -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>Données</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"50.7\" cy=\"-25\" rx=\"50.89\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.7\" y=\"-21.3\" font-family=\"Times,serif\" font-size=\"14.00\">Données</text>\n",
       "</g>\n",
       "<!-- Données&#45;&gt;Architecture et Methode d&#39;Apprentissage -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>Données&#45;&gt;Architecture et Methode d&#39;Apprentissage</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M101.58,-25C109.53,-25 118.12,-25 127.09,-25\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"127.38,-28.5 137.38,-25 127.38,-21.5 127.38,-28.5\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x7f4b9b929c10>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gv('''\"Architecture et Methode d'Apprentissage\"[shape=box3d width=1 height=0.7]\n",
    "Données->\"Architecture et Methode d'Apprentissage\"-> Capacité''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
